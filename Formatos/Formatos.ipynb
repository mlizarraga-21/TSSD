{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manejo básico de formatos y pandas\n",
    "Sistemas Inteligentes basados en WWW y LLM (TSSD)\n",
    "Mario Alberto Lizarraga Reyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctica 1\n",
    "Lea uno de los archivos customers, imprima en pantalla el número de registros leídos y\n",
    "los primeros n registros. Después, introduzca código para tratar de determinar si el archivo CSV que se recibe de\n",
    "entrada posee un encabezado y manejarlo adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo tiene encabezado: True\n",
      "Número de registros leídos: 100\n",
      "\n",
      "Encabezado del archivo:\n",
      "['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website']\n",
      "\n",
      "Primeros 5 registros:\n",
      "['1', 'DD37Cf93aecA6Dc', 'Sheryl', 'Baxter', 'Rasmussen Group', 'East Leonard', 'Chile', '229.077.5154', '397.884.0519x718', 'zunigavanessa@smith.info', '2020-08-24', 'http://www.stephenson.com/']\n",
      "['2', '1Ef7b82A4CAAD10', 'Preston', 'Lozano', 'Vega-Gentry', 'East Jimmychester', 'Djibouti', '5153435776', '686-620-1820x944', 'vmata@colon.com', '2021-04-23', 'http://www.hobbs.com/']\n",
      "['3', '6F94879bDAfE5a6', 'Roy', 'Berry', 'Murillo-Perry', 'Isabelborough', 'Antigua and Barbuda', '+1-539-402-0259', '(496)978-3969x58947', 'beckycarr@hogan.com', '2020-03-25', 'http://www.lawrence.com/']\n",
      "['4', '5Cef8BFA16c5e3c', 'Linda', 'Olsen', 'Dominguez, Mcmillan and Donovan', 'Bensonview', 'Dominican Republic', '001-808-617-6467x12895', '+1-813-324-8756', 'stanleyblackwell@benson.org', '2020-06-02', 'http://www.good-lyons.com/']\n",
      "['5', '053d585Ab6b3159', 'Joanna', 'Bender', 'Martin, Lang and Andrade', 'West Priscilla', 'Slovakia (Slovak Republic)', '001-234-203-0635x76146', '001-199-446-3860x3486', 'colinalvarado@miles.net', '2021-04-17', 'https://goodwin-ingram.com/']\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\customers-100.csv'\n",
    "\n",
    "# Leer archivo CSV\n",
    "with open(file_path, mode='r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    content = list(reader)  # Leer el contenido en una lista\n",
    "\n",
    "# Usar Sniffer para determinar si tiene encabezado\n",
    "with open(file_path, mode='r') as file:\n",
    "    has_header = csv.Sniffer().has_header(file.read())\n",
    "    print(\"El archivo tiene encabezado:\", has_header)\n",
    "\n",
    "# Separar encabezado y datos\n",
    "if has_header:\n",
    "    header = content[0]  # Ecabezado\n",
    "    data = content[1:]   # Los registros restantes son los datos\n",
    "else:\n",
    "    header = None  \n",
    "    data = content  # Todos los registros son datos\n",
    "\n",
    "print(\"Número de registros leídos:\", len(data))\n",
    "\n",
    "if has_header:\n",
    "    print(\"\\nEncabezado del archivo:\")\n",
    "    print(header)\n",
    "\n",
    "print(\"\\nPrimeros 5 registros:\")\n",
    "for registro in data[:5]:\n",
    "    print(registro)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script se divide en dos partes fundamentales, la detección del header y el procesado en base a esto, para la detección se utilizó la clase sniffer, la cual contiene la función has_header(), dicha función analiza el texto y regresa true si la primera row es una serie de headers. Usando esto como punto de partida, si el archivo contiene header lo separamos de la data, de otra manera, todo se define como data.\n",
    "\n",
    "Clase sniffer\n",
    "https://docs.python.org/3/library/csv.html#csv.Sniffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctica 2\n",
    "Ahora hay que abrir un archivo en modo escritura para escribir en el mismo, trate de introducir un nuevo renglón. Ahora intente introducir una nueva columna. Escriba el archivo a disco y verifique que todo quedó como se esperaba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo original:\n",
      "['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website']\n",
      "['1', 'DD37Cf93aecA6Dc', 'Sheryl', 'Baxter', 'Rasmussen Group', 'East Leonard', 'Chile', '229.077.5154', '397.884.0519x718', 'zunigavanessa@smith.info', '2020-08-24', 'http://www.stephenson.com/']\n",
      "['2', '1Ef7b82A4CAAD10', 'Preston', 'Lozano', 'Vega-Gentry', 'East Jimmychester', 'Djibouti', '5153435776', '686-620-1820x944', 'vmata@colon.com', '2021-04-23', 'http://www.hobbs.com/']\n",
      "\n",
      "Archivo modificado:\n",
      "['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Notes']\n",
      "['1', 'DD37Cf93aecA6Dc', 'Sheryl', 'Baxter', 'Rasmussen Group', 'East Leonard', 'Chile', '229.077.5154', '397.884.0519x718', 'zunigavanessa@smith.info', '2020-08-24', 'http://www.stephenson.com/', 'Note 1']\n",
      "['2', '1Ef7b82A4CAAD10', 'Preston', 'Lozano', 'Vega-Gentry', 'East Jimmychester', 'Djibouti', '5153435776', '686-620-1820x944', 'vmata@colon.com', '2021-04-23', 'http://www.hobbs.com/', 'Note 2']\n",
      "['3', 'CC56Df23bfaB7Ed', 'Taylor', 'Smith', 'TechCorp', 'New City', 'USA', '123-456-7890', '098-765-4321', 'taylor.smith@example.com', '2022-05-15', 'http://www.techcorp.com/', 'Note 3']\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\P-2.csv'\n",
    "\n",
    "# Encabezados y datos (mismo formato que el ejercicio anterior)\n",
    "fields = ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website']\n",
    "rows = [\n",
    "    ['1', 'DD37Cf93aecA6Dc', 'Sheryl', 'Baxter', 'Rasmussen Group', 'East Leonard', 'Chile', '229.077.5154', '397.884.0519x718', 'zunigavanessa@smith.info', '2020-08-24', 'http://www.stephenson.com/'],\n",
    "    ['2', '1Ef7b82A4CAAD10', 'Preston', 'Lozano', 'Vega-Gentry', 'East Jimmychester', 'Djibouti', '5153435776', '686-620-1820x944', 'vmata@colon.com', '2021-04-23', 'http://www.hobbs.com/']\n",
    "]\n",
    "\n",
    "# Escribir datos iniciales en el archivo\n",
    "with open(file_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n",
    "    csvwriter.writerows(rows)\n",
    "\n",
    "# Leer e imprimir archivo original\n",
    "print(\"Archivo original:\")\n",
    "with open(file_path, 'r', newline='') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        print(row)\n",
    "\n",
    "# Definimos nueva fila y nueva columna\n",
    "new_row = ['3', 'CC56Df23bfaB7Ed', 'Taylor', 'Smith', 'TechCorp', 'New City', 'USA', '123-456-7890', '098-765-4321', 'taylor.smith@example.com', '2022-05-15', 'http://www.techcorp.com/']\n",
    "new_column = 'Notes'\n",
    "\n",
    "# Modificar el archivo para agregar la nueva columna\n",
    "with open(file_path, 'r', newline='') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    data = list(csvreader) \n",
    "\n",
    "# Agregar la nueva fila\n",
    "data.append(new_row)\n",
    "\n",
    "# Agregar la nueva columna usando append\n",
    "data[0].append(new_column)  # Modificar encabezado\n",
    "for i, row in enumerate(data[1:], start=1):\n",
    "    row.append(f'Note {i}')  # Valores arbitrarios para rellenar la nueva columna\n",
    "\n",
    "# Escribir los datos modificados en el archivo\n",
    "with open(file_path, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerows(data)\n",
    "\n",
    "# Leer e imprimir archivo modificado\n",
    "print(\"\\nArchivo modificado:\")\n",
    "with open(file_path, 'r', newline='') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, se utilizó el formato del archivo customers, al cual se le agregó un row con datos nuevos, y una columna nueva para notas, para esto se utilizó el método append además de iterar en cada row para agregar datos arbitrarios en la nueva columna. En la consola se puede que el código si modifica el archivo y además se verificó en disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctica 3\n",
    "Con pandas.read_csv() se puede leer un archivo CSV. Una vez que está la información del archivo en un dataframe, se puede manipular de muchas maneras. Lea uno de los archivos people y ponga el contenido en un dataframe. Enseguida, agregue una nueva columna, luego un nuevo renglón. Con el dataframe resultante de haber hecho ambas operaciones, genere un nuevo archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultimos dos valores de los ultimos dos registros del archivo original\n",
      "                   Phone Date of birth              Job Title\n",
      "98  001-273-685-6932x092    2012-04-12   Broadcast journalist\n",
      "99   (341)594-6554x44657    2016-11-15  IT sales professional\n",
      "Ultimos dos valores con columna agregada\n",
      "   Date of birth              Job Title Nueva Columna\n",
      "98    2012-04-12   Broadcast journalist      Valor 99\n",
      "99    2016-11-15  IT sales professional     Valor 100\n",
      "Ultimos dos valores de los ultimos dos registros (deberia estar el nuevo renglon)\n",
      "    Date of birth              Job Title Nueva Columna\n",
      "99     2016-11-15  IT sales professional     Valor 100\n",
      "100    1990-01-01         Dummy Engineer   Dummy Value\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\people-100.csv'\n",
    "\n",
    "# Leer el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Ultimos dos valores de los ultimos dos registros del archivo original\")\n",
    "print(df.iloc[-2:, -3:])  # Impriumir los últimos 2 datos disponibles de los últimos 2 registros\n",
    "\n",
    "# Nueva columna\n",
    "df[\"Nueva Columna\"] = [f\"Valor {i+1}\" for i in range(len(df))]\n",
    "\n",
    "print(\"Ultimos dos valores con columna agregada\")\n",
    "print(df.iloc[-2:, -3:])  # Imprimir los últimos 3 datos de los últimos 2 registros con la nueva columna\n",
    "\n",
    "# Crear un nuevo renglón con valores dummy\n",
    "nuevo_renglon = pd.DataFrame({\n",
    "    \"Index\": [len(df) + 1],\n",
    "    \"User Id\": [\"ZZ99Abc123\"],\n",
    "    \"First Name\": [\"Taylor\"],\n",
    "    \"Last Name\": [\"Doe\"],\n",
    "    \"Sex\": [\"Non-binary\"],\n",
    "    \"Email\": [\"taylor.doe@example.com\"],\n",
    "    \"Phone\": [\"555-1234x5678\"],\n",
    "    \"Date of birth\": [\"1990-01-01\"],\n",
    "    \"Job Title\": [\"Dummy Engineer\"],\n",
    "    \"Nueva Columna\": [\"Dummy Value\"],\n",
    "})\n",
    "\n",
    "# Agregar el nuevo renglón al DataFrame\n",
    "df = pd.concat([df, nuevo_renglon], ignore_index=True)\n",
    "\n",
    "print(\"Ultimos dos valores de los ultimos dos registros (deberia estar el nuevo renglon)\")\n",
    "print(df.iloc[-2:, -3:])  # Mostrar los últimos 3 datos de los últimos 2 registros incluyendo el nuevo\n",
    "\n",
    "# Sobrescribir el archivo con las modificaciones\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver en la consola, en el primer print se muestran los ultimos dos registros del archivo original, despues se agrega la nueva columna la cual tiene un valor arbitrario, y por ultimo se agrega el nuevo renglon con los valores dummy solo para ejemplificar, despues de este ultimo print ademas, se sobre escribe el archivo para guardar las modificaciones usando pandas. Desde mi opinión, el procesado de esta manera es más sencillo de ver y entender y también considero más fáciles de usar los métodos dentro de los dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctica 5 y 6\n",
    "Leer un archivo JSON es en esencia igual a cualquier otro tipo de archivo. Una vez hecha la lectura hay que cargar el texto del archivo JSON a objetos de python; para ello la biblioteca json tiene los métodos load() y loads(). Es importante saber que dichos métodos trabajan como en la tabla de conversiones. Para verificar lo anterior, primero lea un archivo con los contenidos de Example 2 ydespliegue el objeto python resultante; haga lo mismo para Example 4 y luego para Example 5. Tras tener en memoria los objetos de la práctica anterior, use json.dumps() para escribir los objetos a sus correspondientes archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"color\": \"red\",\n",
      "        \"value\": \"#f00\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"green\",\n",
      "        \"value\": \"#0f0\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"blue\",\n",
      "        \"value\": \"#00f\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"cyan\",\n",
      "        \"value\": \"#0ff\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"magenta\",\n",
      "        \"value\": \"#f0f\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"yellow\",\n",
      "        \"value\": \"#ff0\"\n",
      "    },\n",
      "    {\n",
      "        \"color\": \"black\",\n",
      "        \"value\": \"#000\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "example2_path=r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\Example_2.json'\n",
    "\n",
    "# Función para validar y cargar un archivo JSON\n",
    "def load_and_validate_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        print(json.dumps(data, indent=4))\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al cargar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Leer y guardar archivo Example_2.json\n",
    "example_2_data = load_and_validate_json(example2_path)\n",
    "if example_2_data:\n",
    "    with open(\"output_example_2.json\", \"w\") as file:\n",
    "        json.dump(example_2_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"0001\",\n",
      "    \"type\": \"donut\",\n",
      "    \"name\": \"Cake\",\n",
      "    \"ppu\": 0.55,\n",
      "    \"batters\": {\n",
      "        \"batter\": [\n",
      "            {\n",
      "                \"id\": \"1001\",\n",
      "                \"type\": \"Regular\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"1002\",\n",
      "                \"type\": \"Chocolate\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"1003\",\n",
      "                \"type\": \"Blueberry\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"1004\",\n",
      "                \"type\": \"Devil's Food\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"topping\": [\n",
      "        {\n",
      "            \"id\": \"5001\",\n",
      "            \"type\": \"None\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5002\",\n",
      "            \"type\": \"Glazed\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5005\",\n",
      "            \"type\": \"Sugar\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5007\",\n",
      "            \"type\": \"Powdered Sugar\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5006\",\n",
      "            \"type\": \"Chocolate with Sprinkles\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5003\",\n",
      "            \"type\": \"Chocolate\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"5004\",\n",
      "            \"type\": \"Maple\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example4_path=r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\Example_4.json'\n",
    "\n",
    "# Leer y guardar archivo Example_4.json\n",
    "example_4_data = load_and_validate_json(example4_path)\n",
    "if example_4_data:\n",
    "    with open(\"output_example_4.json\", \"w\") as file:\n",
    "        json.dump(example_4_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"0001\",\n",
      "        \"type\": \"donut\",\n",
      "        \"name\": \"Cake\",\n",
      "        \"ppu\": 0.55,\n",
      "        \"batters\": {\n",
      "            \"batter\": [\n",
      "                {\n",
      "                    \"id\": \"1001\",\n",
      "                    \"type\": \"Regular\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"1002\",\n",
      "                    \"type\": \"Chocolate\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"1003\",\n",
      "                    \"type\": \"Blueberry\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"1004\",\n",
      "                    \"type\": \"Devil's Food\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"topping\": [\n",
      "            {\n",
      "                \"id\": \"5001\",\n",
      "                \"type\": \"None\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5002\",\n",
      "                \"type\": \"Glazed\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5005\",\n",
      "                \"type\": \"Sugar\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5007\",\n",
      "                \"type\": \"Powdered Sugar\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5006\",\n",
      "                \"type\": \"Chocolate with Sprinkles\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5003\",\n",
      "                \"type\": \"Chocolate\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5004\",\n",
      "                \"type\": \"Maple\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"0002\",\n",
      "        \"type\": \"donut\",\n",
      "        \"name\": \"Raised\",\n",
      "        \"ppu\": 0.55,\n",
      "        \"batters\": {\n",
      "            \"batter\": [\n",
      "                {\n",
      "                    \"id\": \"1001\",\n",
      "                    \"type\": \"Regular\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"topping\": [\n",
      "            {\n",
      "                \"id\": \"5001\",\n",
      "                \"type\": \"None\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5002\",\n",
      "                \"type\": \"Glazed\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5005\",\n",
      "                \"type\": \"Sugar\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5003\",\n",
      "                \"type\": \"Chocolate\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5004\",\n",
      "                \"type\": \"Maple\"\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"0003\",\n",
      "        \"type\": \"donut\",\n",
      "        \"name\": \"Old Fashioned\",\n",
      "        \"ppu\": 0.55,\n",
      "        \"batters\": {\n",
      "            \"batter\": [\n",
      "                {\n",
      "                    \"id\": \"1001\",\n",
      "                    \"type\": \"Regular\"\n",
      "                },\n",
      "                {\n",
      "                    \"id\": \"1002\",\n",
      "                    \"type\": \"Chocolate\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        \"topping\": [\n",
      "            {\n",
      "                \"id\": \"5001\",\n",
      "                \"type\": \"None\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5002\",\n",
      "                \"type\": \"Glazed\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5003\",\n",
      "                \"type\": \"Chocolate\"\n",
      "            },\n",
      "            {\n",
      "                \"id\": \"5004\",\n",
      "                \"type\": \"Maple\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "example5_path=r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\Example_5.json'\n",
    "\n",
    "# Leer y guardar archivo Example_5.json\n",
    "example_5_data = load_and_validate_json(example5_path)\n",
    "if example_5_data:\n",
    "    with open(\"output_example_5.json\", \"w\") as file:\n",
    "        json.dump(example_5_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta practica, hice una funcion por separado load_and_validate_json() para hacer una llamada por archivo y que el procedimiento fuera estandar para cada uno de los archivos, algo a notar es que estaba teniendo problemas de formato en mis archivos, dicho error se corrigió al momento de definir la función load and validate, por lo que no encontré exactamente el problema ni la solución si no un workaround mientras trataba de ver el error que me arrojaba la clase json.JSONDecodeError. La solución queda pendiente para mi ya que no he encontrado nada en específico hasta el momento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Práctica 7\n",
    "Una manera muy directa de cargar los contenidos de archivos JSON a un dataframe de pandas es mediante el método read_json(). Tome los contenidos del Example 2 y cárguelos a un dataframe.\n",
    "Una vez en el dataframe se pueden manipular los contenidos de muchas formas. Pruebe “regresando” los contenidos a JSON, pero usando diferentes orientaciones con parámetros del método to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenido del DataFrame con to_string():\n",
      "     color value\n",
      "0      red  #f00\n",
      "1    green  #0f0\n",
      "2     blue  #00f\n",
      "3     cyan  #0ff\n",
      "4  magenta  #f0f\n",
      "5   yellow  #ff0\n",
      "6    black  #000\n"
     ]
    }
   ],
   "source": [
    "example2_path=r'C:\\Users\\lizar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\Scripts\\Escuela\\Distribuidos\\Example_2.json'\n",
    "\n",
    "def load_and_validate_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al cargar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Cargar example 2\n",
    "example_2_data = load_and_validate_json(example2_path)\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(example_2_data)\n",
    "print(\"\\nContenido del DataFrame con to_string():\")\n",
    "print(df.to_string())\n",
    "\n",
    "# Archivos para las orientaciones\n",
    "split_path = \"output_example_2_split.json\"\n",
    "index_path = \"output_example_2_index.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenido del archivo JSON con orientación 'split':\n",
      "{\n",
      "    \"columns\":[\n",
      "        \"color\",\n",
      "        \"value\"\n",
      "    ],\n",
      "    \"index\":[\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5,\n",
      "        6\n",
      "    ],\n",
      "    \"data\":[\n",
      "        [\n",
      "            \"red\",\n",
      "            \"#f00\"\n",
      "        ],\n",
      "        [\n",
      "            \"green\",\n",
      "            \"#0f0\"\n",
      "        ],\n",
      "        [\n",
      "            \"blue\",\n",
      "            \"#00f\"\n",
      "        ],\n",
      "        [\n",
      "            \"cyan\",\n",
      "            \"#0ff\"\n",
      "        ],\n",
      "        [\n",
      "            \"magenta\",\n",
      "            \"#f0f\"\n",
      "        ],\n",
      "        [\n",
      "            \"yellow\",\n",
      "            \"#ff0\"\n",
      "        ],\n",
      "        [\n",
      "            \"black\",\n",
      "            \"#000\"\n",
      "        ]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "df.to_json(split_path, orient=\"split\", indent=4) #Orientacion a split\n",
    "print(f\"\\nContenido del archivo JSON con orientación 'split':\")\n",
    "with open(split_path, \"r\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contenido del archivo JSON con orientación 'index':\n",
      "{\n",
      "    \"0\":{\n",
      "        \"color\":\"red\",\n",
      "        \"value\":\"#f00\"\n",
      "    },\n",
      "    \"1\":{\n",
      "        \"color\":\"green\",\n",
      "        \"value\":\"#0f0\"\n",
      "    },\n",
      "    \"2\":{\n",
      "        \"color\":\"blue\",\n",
      "        \"value\":\"#00f\"\n",
      "    },\n",
      "    \"3\":{\n",
      "        \"color\":\"cyan\",\n",
      "        \"value\":\"#0ff\"\n",
      "    },\n",
      "    \"4\":{\n",
      "        \"color\":\"magenta\",\n",
      "        \"value\":\"#f0f\"\n",
      "    },\n",
      "    \"5\":{\n",
      "        \"color\":\"yellow\",\n",
      "        \"value\":\"#ff0\"\n",
      "    },\n",
      "    \"6\":{\n",
      "        \"color\":\"black\",\n",
      "        \"value\":\"#000\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "df.to_json(index_path, orient=\"index\", indent=4) #Orientacion a index\n",
    "print(f\"\\nContenido del archivo JSON con orientación 'index':\")\n",
    "with open(index_path, \"r\") as file:\n",
    "    print(file.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ultima práctica, fue la que más sencilla se me hizo, apoyandome del método to_json y simplemente especificando las distintas orientaciones, sin embargo también usé la función mencionada anteriormente por los mismos motivos.\n",
    "\n",
    "A manera de conclusión, me agradó trabajar con los distintos formatos, especialmente JSON ya que no estoy muy familiarizado con el al nivel de CSV, de igual manera, la documentación fue de mucha ayuda para el uso de las librerías y me ayudó a entender más el uso de sus métodos y clases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
