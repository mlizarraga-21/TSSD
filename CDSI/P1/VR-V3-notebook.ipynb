{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76cf145",
   "metadata": {},
   "source": [
    "# ðŸ“Š Audio Data Preprocessing (with Cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754840f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Cleanup old models, scalers, and feature CSVs\n",
    "for method in [1, 2, 3]:\n",
    "    if os.path.exists(f'model_method_{method}.pkl'):\n",
    "        os.remove(f'model_method_{method}.pkl')\n",
    "    if os.path.exists(f'scaler_method_{method}.pkl'):\n",
    "        os.remove(f'scaler_method_{method}.pkl')\n",
    "    if os.path.exists(f'features_method_{method}.csv'):\n",
    "        os.remove(f'features_method_{method}.csv')\n",
    "if os.path.exists('label_encoder.pkl'):\n",
    "    os.remove('label_encoder.pkl')\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3  # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Load noise files from the \"noise\" directory\n",
    "def load_noise_files(noise_dir):\n",
    "    noise_files = []\n",
    "    for file in os.listdir(noise_dir):\n",
    "        if file.endswith('.wav') or file.endswith('.mp3'):\n",
    "            audio, _ = librosa.load(os.path.join(noise_dir, file), sr=SAMPLE_RATE, duration=DURATION)\n",
    "            if len(audio) < SAMPLES_PER_TRACK:\n",
    "                padding = SAMPLES_PER_TRACK - len(audio)\n",
    "                audio = np.pad(audio, (0, padding), mode='constant')\n",
    "            noise_files.append(audio)\n",
    "    return noise_files\n",
    "\n",
    "# Data processing functions\n",
    "def load_audio_file(file_path, duration=DURATION, sample_rate=SAMPLE_RATE):\n",
    "    audio, sr = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "    if len(audio) < SAMPLES_PER_TRACK:\n",
    "        padding = SAMPLES_PER_TRACK - len(audio)\n",
    "        audio = np.pad(audio, (0, padding), mode='constant')\n",
    "    else:\n",
    "        audio = audio[:SAMPLES_PER_TRACK]\n",
    "    return audio\n",
    "\n",
    "def reduce_noise(audio, sr=SAMPLE_RATE):\n",
    "    return librosa.effects.preemphasis(audio)\n",
    "\n",
    "def augment_audio(audio, noise_files):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    audio_noise = audio + 0.005 * noise\n",
    "\n",
    "    audio_with_real_noise = []\n",
    "    for noise_sample in noise_files:\n",
    "        if len(noise_sample) == len(audio):\n",
    "            mixed_audio = audio + 0.02 * noise_sample\n",
    "            audio_with_real_noise.append(mixed_audio)\n",
    "\n",
    "    audio_pitch_shift = librosa.effects.pitch_shift(audio, sr=SAMPLE_RATE, n_steps=4)\n",
    "    audio_stretch = librosa.effects.time_stretch(audio, rate=0.8)\n",
    "\n",
    "    return [audio_noise, audio_pitch_shift, audio_stretch] + audio_with_real_noise\n",
    "\n",
    "def extract_features(audio, sr=SAMPLE_RATE):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio)\n",
    "    rmse = librosa.feature.rms(y=audio)\n",
    "    tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "\n",
    "    features = np.hstack([\n",
    "        np.mean(mfccs, axis=1),\n",
    "        np.mean(chroma, axis=1),\n",
    "        np.mean(spectral_contrast, axis=1),\n",
    "        np.mean(zero_crossing_rate),\n",
    "        np.mean(rmse),\n",
    "        tempo\n",
    "    ])\n",
    "\n",
    "    return features\n",
    "\n",
    "# Process audio files\n",
    "def process_audio_files(directory, noise_dir='noise'):\n",
    "    dataframes = {1: [], 2: [], 3: []}\n",
    "    labels = {1: [], 2: [], 3: []}\n",
    "    noise_files = load_noise_files(os.path.join(directory, noise_dir))\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".wav\") or filename.endswith(\".mp3\") and not filename.startswith('noise'):\n",
    "            name, method_audio = filename.rsplit('-', 1)\n",
    "            method_part, _ = method_audio.split('.')\n",
    "            method = int(method_part[:2])\n",
    "\n",
    "            if method not in dataframes:\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            audio = load_audio_file(file_path)\n",
    "            audio = reduce_noise(audio)\n",
    "            features = extract_features(audio)\n",
    "\n",
    "            dataframes[method].append(features)\n",
    "            labels[method].append(name)\n",
    "\n",
    "            # Data augmentation with both synthetic and real noise\n",
    "            augmented_audios = augment_audio(audio, noise_files)\n",
    "            for aug_audio in augmented_audios:\n",
    "                aug_features = extract_features(aug_audio)\n",
    "                dataframes[method].append(aug_features)\n",
    "                labels[method].append(name)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    for method, features in dataframes.items():\n",
    "        method_labels = labels[method]\n",
    "        encoded_labels = le.fit_transform(method_labels)\n",
    "\n",
    "        df = pd.DataFrame(features)\n",
    "        df['label'] = encoded_labels\n",
    "        df['person'] = method_labels\n",
    "\n",
    "        # Save feature vectors for manual inspection\n",
    "        df.to_csv(f'features_method_{method}.csv', index=False)\n",
    "\n",
    "    joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "# Specify the directory containing audio files\n",
    "directory = \"path_to_your_audio_files\"\n",
    "process_audio_files(directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db74d1",
   "metadata": {},
   "source": [
    "# ðŸ¤– Model Training with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f058bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training models for each method with cross-validation\n",
    "for method in [1, 2, 3]:\n",
    "    print(f\"--- Training Model for Method {method} ---\")\n",
    "    \n",
    "    df = pd.read_csv(f'features_method_{method}.csv')\n",
    "    X = df.drop(['label', 'person'], axis=1).values\n",
    "    y = df['label'].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators=100)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(classifier, X, y, cv=5)\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Mean CV Accuracy: {cv_scores.mean() * 100:.2f}%\")\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Accuracy Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=df['person'].unique(), yticklabels=df['person'].unique())\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix for Method {method}')\n",
    "    plt.show()\n",
    "\n",
    "    # Save models and scalers\n",
    "    joblib.dump(classifier, f'model_method_{method}.pkl')\n",
    "    joblib.dump(scaler, f'scaler_method_{method}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d852a3f",
   "metadata": {},
   "source": [
    "# ðŸŽ¤ Real-Time Audio Recording & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176df449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3  # seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Load models and scalers\n",
    "models = {method: joblib.load(f'model_method_{method}.pkl') for method in [1, 2, 3]}\n",
    "scalers = {method: joblib.load(f'scaler_method_{method}.pkl') for method in [1, 2, 3]}\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Functions for real-time recording and prediction\n",
    "def record_audio():\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(SAMPLES_PER_TRACK), samplerate=SAMPLE_RATE, channels=1)\n",
    "    sd.wait()\n",
    "    print(\"Recording complete.\")\n",
    "    return audio.flatten()\n",
    "\n",
    "def extract_features(audio):\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=SAMPLE_RATE, n_mfcc=40)\n",
    "    return np.mean(mfccs.T, axis=0)\n",
    "\n",
    "def predict(audio):\n",
    "    features = extract_features(audio).reshape(1, -1)\n",
    "    predictions = {}\n",
    "\n",
    "    for method in models:\n",
    "        scaled_features = scalers[method].transform(features)\n",
    "        pred = models[method].predict(scaled_features)\n",
    "        predictions[method] = label_encoder.inverse_transform(pred)[0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Run real-time prediction\n",
    "audio = record_audio()\n",
    "predictions = predict(audio)\n",
    "for method, prediction in predictions.items():\n",
    "    print(f\"Prediction for Method {method}: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
